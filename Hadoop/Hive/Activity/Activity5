hive> show databases;

--To start, we shall first create a database named office:
hive> create database office;

--Set office as the default DB using the following query:
hive> use office;
--Use the query shown below to create a table named employee:
hive> CREATE TABLE employee
    > (id INT, name STRING, dept STRING, yoj INT, salary INT)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > TBLPROPERTIES ("skip.header.line.count"="1");
    --Once the table has been created, you can use the DESCRIBE clause to see the structure of the table:
    hive> DESCRIBE employee;
    --To add into the employee table from a local file, enter the following query:
    hive> LOAD DATA LOCAL INPATH
    > '/EmpData.csv'
    > INTO TABLE employee;
   -- To see the data that has been loaded into the employee table, use the SELECT query:
    hive> SELECT * FROM employee;
    --In the case of the second SELECT query, or any of the queries listed below, Hive will trigger either a Map or Reduce or both jobs, based on the computation needed:
    # Column operations
hive> SELECT  id, name FROM employee;
# Row operation
hive> SELECT * FROM employee WHERE salary > 30000;
# Column operation that need aggregation
hive> SELECT count(*) FROM employee; 
--command to export
hive> INSERT OVERWRITE [LOCAL] DIRECTORY directory
#Exports to HDFS directory
hive> INSERT OVERWRITE DIRECTORY '/user/root/output/export'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM emp.employee;

    --To export results to local filesystem, run the following query:
    #Exports to LOCAL directory
hive> INSERT OVERWRITE LOCAL DIRECTORY '/export' 
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM emp.employee;